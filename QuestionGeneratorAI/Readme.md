# ğŸ¦™ Llama Document Prompt API

Uma API poderosa que combina modelos LLaMA da Hugging Face, OpenAI, FastAPI e Fitz para interpretar documentos e responder a perguntas personalizadas. Basta enviar um arquivo `.pdf`, `.md` ou `.docx` e fazer um prompt sobre o conteÃºdo!

---

## ğŸ“¸ VisÃ£o Geral

> Transforme documentos em conhecimento com inteligÃªncia artificial.

---

## ğŸš€ Funcionalidades

- ğŸ“„ Suporte a arquivos `.pdf`, `.md`, `.docx`
- ğŸ§  Processamento com modelo LLaMA via [Hugging Face Router](https://router.huggingface.co/v1)
- ğŸ¤– GeraÃ§Ã£o de respostas com OpenAI
- âš¡ API rÃ¡pida com FastAPI
- ğŸ” ExtraÃ§Ã£o de texto com Fitz

---

## ğŸ§° Tecnologias Utilizadas

| Tecnologia           | FunÃ§Ã£o Principal                          |
|----------------------|-------------------------------------------|
| LLaMA (Hugging Face) | InterpretaÃ§Ã£o semÃ¢ntica dos documentos    |
| OpenAI               | GeraÃ§Ã£o de respostas contextuais          |
| FastAPI              | Estrutura da API                          |
| Fitz                 | ExtraÃ§Ã£o de texto de arquivos PDF         |

---

## ğŸ“¦ Como Usar

### 1. InstalaÃ§Ã£o

```bash
git clone https://github.com/Joao-Adegas/QuestionGeneratorAI
cd QuestionGeneratorAI
pip install -r requirements.txt
```

## ğŸ§‘â€ğŸ’» Passo a Passo para Iniciar o Projeto

Este guia assume que vocÃª jÃ¡ possui um ambiente virtual Python ativo. Se ainda nÃ£o tiver, vocÃª pode criar um com:

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
```

## ğŸš€ 3. Iniciar a API com Uvicorn
Execute o servidor local com FastAPI:
```bash
uvicorn main:app --reload
```
